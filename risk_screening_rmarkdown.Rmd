---
title: "Screening Text for Risk Programmatically"
author: "Michael Mullarkey"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
geometry: margin=0.50in
---

```{r setup, include=FALSE, cache = FALSE}
require("knitr")
## setting working directory
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, include = FALSE)

```

```{r loading packages}

if(!require(tidymodels)){install.packages('tidymodels')}
library(tidymodels)
if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)
if(!require(tidytext)){install.packages('tidytext')}
library(tidytext)
if(!require(readr)){install.packages('readr')}
library(readr)
if(!require(skimr)){install.packages('skimr')}
library(skimr)
if(!require(glue)){install.packages('glue')}
library(glue)
if(!require(diffdf)){install.packages('diffdf')}
library(diffdf)
if(!require(doMC)){install.packages('doMC')}
library(doMC)
if(!require(tictoc)){install.packages('tictoc')}
library(tictoc)
if(!require(torch)){install.packages('torch')}
library(torch)
if(!require(tabnet)){install.packages('tabnet')}
library(tabnet)
if(!require(vip)){install.packages('vip')}
library(vip)


```

```{r loading labeled tweet data to test whether it works}

## Data labeled for SITB or no SITB content already and described in this post: https://towardsdatascience.com/building-a-suicidal-tweet-classifier-using-nlp-ff6ccd77e971

urlfile="https://raw.githubusercontent.com/AminuIsrael/Predicting-Suicide-Ideation/master/suicidal_data.csv"

sitb_text <- read_csv(url(urlfile))

# No leading or trailing whitespace in the character variables

skim(sitb_text)

# Can also look at the data using glimpse

glimpse(sitb_text)

# Let's convert to more meaningful metric rather than 1/0

sitb_text <- sitb_text %>% 
  mutate(label = factor(case_when(
    label == 1 ~ "SITB",
    label == 0 ~ "No SITB",
    TRUE ~ NA_character_
    
  ))) %>% 
  na.omit() # Dropping NAs

# Let's see the breakdown of SITB/No SITB Tweets, looks pretty well-balanced

sitb_text %>% 
  count(label) %>% 
  mutate(percent = 100*(n/sum(n)))

```
```{r detecting presence of certain risk related words}

# What we want is first a tidy function that can return Yes or No for the presence of a certain word/regular expression, which we can do with stringr

# No function

no_func_ex <- sitb_text %>% 
  mutate(suic = str_detect(tweet, "suic")) %>% 
  print()

# Tidy function

detect_word <- function(.data, word){
  
  .data %>% 
  mutate("{word}" := str_detect(tweet, word))
  
}

tidy_ex <- sitb_text %>% 
  detect_word(word = "suic") %>% 
  print()

# Testing base and tidy function return the same dataframe

diffdf(no_func_ex, tidy_ex)

# Look at the percent of tweets that have an explicit mention of suicide in them by label, and see that there is mention of suicide in some tweets not labeled as containing SITB

tidy_ex %>% 
  group_by(label, suic) %>% 
  tally() %>% 
  mutate(percent = 100*(n/sum(n)))

## Now want to map over a bunch of words and attach them to the original dataframe

words <- c("suicid", "(?<!s)kill", "(?<!stu|la)die(?!go)", "death", "dead(?!line)", "harm", "hurt", 
    "murder", "cut(?!e)", "stab", "burn", "slice", "slash", "slit", "split", 
    "(?<!c)hang(?! *out|ing *out| *around|ing *around)", 
    "shoot", "fire(?!d)", "lynch", "blow.*up", "blow.*brains", "blow.*head", 
    "knife", "razor", "blade", "trigger", "gun", "rifle", "pistol", "glock", "revolver", 
    "muzzle", "bomb", "fertilizer", "rope", "noose", 
    "wrist", "throat", "vein", "artery", 
    "blood", "bleed", 
    "overdose", "pill", "needle", "poison", "bleach", 
    "(?<!anti)depress", "despise", "hate", "worthless", "burden", 
    "end.*life", "take.*life", "better *off", "who *cares", "why *bother", 
    "doesn'?t *matter", "does *not *matter", 
    "(?<!never |don't |don't ever |do not ever |dont |dont ever )give *up", 
    "gave *up", "given *up", 
    "no *one *underst", "nobody *underst",
    "no *one *get", "nobody *gets",
    "no *hope", "don'?t *have *hope", "not *have *hope", "lost *hope", 
    "crazy", "dark", "abus")

sitb_detected <- map_dfc(words, ~{
  
  sitb_text %>% 
    detect_word(word = .x)
  
}) %>% 
  dplyr::select(-contains("label"),-contains("tweet")) %>% 
  bind_cols(sitb_text) %>% 
  rowwise() %>% 
  mutate(any_detect = any(c_across(suicid:abus)), # Seeing if any of the words show up in the text (TRUE if yes, FALSE if no words are in the text)
         sum_detect = sum(c_across(suicid:abus), na.rm = T)) %>% # Seeing how many of the words show up in the text
  ungroup() %>% 
  relocate(label, any_detect, sum_detect, tweet, everything()) %>% 
  arrange(desc(sum_detect)) %>% 
  print()

```

```{r what proportion of SITB and non SITB tweets have these words in them}

# See what percentage of the SITB and non=SITB labeled tweets have any word detected as true

sitb_detected %>% 
  group_by(label, any_detect) %>% 
  tally() %>% 
  mutate(percent = 100*(n/sum(n)))

sitb_detected %>% 
  mutate(any_detect = factor(case_when(
    
    any_detect == FALSE ~ "No SITB",
    any_detect == TRUE ~ "SITB",
    TRUE ~ NA_character_
    
  ))) %>% 
conf_mat(truth = label, estimate = any_detect) %>% 
  summary()


```
```{r looking at breakdown of number of risk words used in the tweet}

sitb_detected %>% 
  group_by(label, sum_detect) %>% 
  tally() %>% 
  mutate(percent = 100*(n/sum(n)))

```

```{r using just the presence absence and sum data to predict label}

# Removing the text

sitb_no_text <- sitb_detected %>% 
  dplyr::select(-tweet)

# Doing a reproducible training/testing split

set.seed(33)
split_sitb <- initial_split(sitb_no_text, prop = 0.8, strata = label)

train_sitb <- training(split_sitb)
test_sitb <- testing(split_sitb)

# Creating a boosted tree model

xgb_mod <- boost_tree(
  trees = 1000, 
  tree_depth = tune(), min_n = tune(), 
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(), mtry = tune(),         ## randomness
  learn_rate = tune(),                         ## step size
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

# Create recipe

rec_boost <- 
  recipe(label ~ ., data = train_sitb)

## And add the recipe + model to workflow

xgb_wf <- workflow() %>%
  add_recipe(rec_boost) %>%
  add_model(xgb_mod)

# We'll use bayesian optimization to find hyperparameters

xgb_set <- parameters(xgb_wf) %>% 
  update(mtry = mtry(c(2L, 20L)))

# Let's create cv folds

set.seed(33)
sitb_folds <- vfold_cv(train_sitb, strata = label, repeats = 5)

# Setting up multicore

doMC::registerDoMC(cores = 7)

# Tuning

keep_pred <- control_resamples(save_pred = T)

tic()
set.seed(33)
xgb_tune_rs <-
  xgb_wf %>% 
  tune_bayes(
    resamples = sitb_folds,
    param_info = xgb_set,
    initial = 5,
    iter = 20,
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 5, verbose = TRUE)
  )
toc()

```


```{r running the final boosted tree model with best hyperparameters}

best_auc <- select_best(xgb_tune_rs, "roc_auc")

final_xgb <- xgb_wf %>% 
  finalize_workflow(best_auc)

## Once hyperparameters are selected in ~45 minutes, the model fitting itself only takes ~2 minutes on 7 cores

tic()
set.seed(33)
boost_fit_rs <-
  final_xgb %>% 
  fit_resamples(sitb_folds, control = keep_pred)
toc()

boost_fit_rs %>% 
  collect_metrics(summarize = TRUE)

xgb_pred <- collect_predictions(boost_fit_rs, summarize = TRUE)


```

```{r predicting using a neural network}

# Creating a tabnet neural network model

nn_mod <- tabnet(epochs = 50, batch_size = 128) %>%
  set_engine("torch", verbose = TRUE) %>%
  set_mode("classification")

# Create recipe

rec_nn <- 
  recipe(label ~ ., data = train_sitb) %>% 
  step_normalize(all_numeric())

## And add the recipe + model to workflow

nn_wf <- workflow() %>%
  add_recipe(rec_nn) %>%
  add_model(nn_mod)

# Let's create cv folds

set.seed(33)
sitb_folds <- vfold_cv(train_sitb, strata = label, repeats = 5)

# Setting up multicore

doMC::registerDoMC(cores = 7)

# Fitting via cross-validation, took nearly 2.5 hours to run on 7 cores

keep_pred <- control_resamples(save_pred = T)

tic()
set.seed(33)
nn_fit_rs <-
  nn_wf %>% 
  fit_resamples(sitb_folds, control = keep_pred)
toc()

nn_fit_rs %>% 
  collect_metrics(summarize = TRUE)

nn_pred <- collect_predictions(nn_fit_rs, summarize = TRUE)

```

```{r fitting the xgboost model to test data}

## See basically 0 decrement in model fit on the test data (literally .0001 difference in AUC value)

sitb_fit <- last_fit(final_xgb, split_sitb)
collect_metrics(sitb_fit)

```
```{r plotting auc curve}

collect_predictions(sitb_fit) %>%
  group_by(id) %>%
  roc_curve(label, `.pred_No SITB`) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  ) +
  coord_equal()

```
```{r looking at metrics beyond auc}

collect_predictions(sitb_fit) %>%
conf_mat(truth = label, estimate = .pred_class) %>% 
  summary()

```


```{r looking at feature importance}

sitb_imp <- sitb_fit$.workflow[[1]] %>%
  pull_workflow_fit() %>% 
  vip() %>% 
  print()

```


```{r saving the model}

# Use the code from the end of this github doc: https://github.com/juliasilge/modelops-playground/blob/master/train-model/train.md
# Also reference Julia Silge's answer to this question: https://stackoverflow.com/questions/66018457/r-tidymodels-what-objects-to-save-for-use-in-production-after-fitting-a-recipe
# Also, an example plumber API to save the model to if we want/need: https://github.com/juliasilge/modelops-playground/blob/master/crash-api/plumber.R

sitb_wf_model <- sitb_fit$.workflow[[1]]

saveRDS(sitb_wf_model, "sitb-wf-model.rds")

```


## Next Steps

* Add features from the text to the model (Next version)
* Work on extending to multiple columns of text (Next version)
* Work on extending to knowing multiple rows are the same person (Next version)

