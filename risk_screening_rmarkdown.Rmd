---
title: "Screening Text for Risk Programmatically"
author: "Michael Mullarkey"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
geometry: margin=0.50in
---

```{r setup, include=FALSE, cache = FALSE}
require("knitr")
## setting working directory
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, include = FALSE)

```

```{r loading packages}

if(!require(tidymodels)){install.packages('tidymodels')}
library(tidymodels)
if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)
if(!require(tidytext)){install.packages('tidytext')}
library(tidytext)
if(!require(textrecipes)){install.packages('textrecipes')}
library(textrecipes)
if(!require(readr)){install.packages('readr')}
library(readr)
if(!require(skimr)){install.packages('skimr')}
library(skimr)
if(!require(glue)){install.packages('glue')}
library(glue)
if(!require(diffdf)){install.packages('diffdf')}
library(diffdf)
if(!require(doMC)){install.packages('doMC')}
library(doMC)
if(!require(tictoc)){install.packages('tictoc')}
library(tictoc)
if(!require(torch)){install.packages('torch')}
library(torch)
if(!require(tabnet)){install.packages('tabnet')}
library(tabnet)
if(!require(vip)){install.packages('vip')}
library(vip)


```

```{r loading labeled tweet data to test whether it works}

## Data labeled for SITB or no SITB content already and described in this post: https://towardsdatascience.com/building-a-suicidal-tweet-classifier-using-nlp-ff6ccd77e971

urlfile="https://raw.githubusercontent.com/AminuIsrael/Predicting-Suicide-Ideation/master/suicidal_data.csv"

sitb_text <- read_csv(url(urlfile))

# No leading or trailing whitespace in the character variables

skim(sitb_text)

# Can also look at the data using glimpse

glimpse(sitb_text)

# Let's convert to more meaningful metric rather than 1/0

sitb_text <- sitb_text %>% 
  mutate(label = factor(case_when(
    label == 1 ~ "SITB",
    label == 0 ~ "No SITB",
    TRUE ~ NA_character_
    
  ))) %>% 
  na.omit() # Dropping NAs

# Let's see the breakdown of SITB/No SITB Tweets, looks pretty well-balanced

sitb_text %>% 
  count(label) %>% 
  mutate(percent = 100*(n/sum(n)))

```
```{r detecting presence of certain risk related words}

# What we want is first a tidy function that can return Yes or No for the presence of a certain word/regular expression, which we can do with stringr

# No function

no_func_ex <- sitb_text %>% 
  mutate(suic = str_detect(tweet, "suic")) %>% 
  print()

# Tidy function

detect_word <- function(.data, word){
  
  .data %>% 
  mutate("{word}" := str_detect(tweet, word))
  
}

tidy_ex <- sitb_text %>% 
  detect_word(word = "suic") %>% 
  print()

# Testing base and tidy function return the same dataframe

diffdf(no_func_ex, tidy_ex)

# Look at the percent of tweets that have an explicit mention of suicide in them by label, and see that there is mention of suicide in some tweets not labeled as containing SITB

tidy_ex %>% 
  group_by(label, suic) %>% 
  tally() %>% 
  mutate(percent = 100*(n/sum(n)))

## Now want to map over a bunch of words and attach them to the original dataframe

words <- c("suicid", "(?<!s)kill", "(?<!stu|la)die(?!go)", "death", "dead(?!line)", "harm", "hurt", 
    "murder", "cut(?!e)", "stab", "burn", "slice", "slash", "slit", "split", 
    "(?<!c)hang(?! *out|ing *out| *around|ing *around)", 
    "shoot", "fire(?!d)", "lynch", "blow.*up", "blow.*brains", "blow.*head", 
    "knife", "razor", "blade", "trigger", "gun", "rifle", "pistol", "glock", "revolver", 
    "muzzle", "bomb", "fertilizer", "rope", "noose", 
    "wrist", "throat", "vein", "artery", 
    "blood", "bleed", 
    "overdose", "pill", "needle", "poison", "bleach", 
    "(?<!anti)depress", "despise", "hate", "worthless", "burden", 
    "end.*life", "take.*life", "better *off", "who *cares", "why *bother", 
    "doesn'?t *matter", "does *not *matter", 
    "(?<!never |don't |don't ever |do not ever |dont |dont ever )give *up", 
    "gave *up", "given *up", 
    "no *one *underst", "nobody *underst",
    "no *one *get", "nobody *gets",
    "no *hope", "don'?t *have *hope", "not *have *hope", "lost *hope", 
    "crazy", "dark", "abus")

sitb_detected <- map_dfc(words, ~{
  
  sitb_text %>% 
    detect_word(word = .x)
  
}) %>% 
  dplyr::select(-contains("label"),-contains("tweet")) %>% 
  bind_cols(sitb_text) %>% 
  rowwise() %>% 
  mutate(any_detect = any(c_across(suicid:abus)), # Seeing if any of the words show up in the text (TRUE if yes, FALSE if no words are in the text)
         sum_detect = sum(c_across(suicid:abus), na.rm = T)) %>% # Seeing how many of the words show up in the text
  ungroup() %>% 
  relocate(label, any_detect, sum_detect, tweet, everything()) %>% 
  arrange(desc(sum_detect)) %>% 
  print()

```

```{r what proportion of SITB and non SITB tweets have these words in them}

# See what percentage of the SITB and non=SITB labeled tweets have any word detected as true

sitb_detected %>% 
  group_by(label, any_detect) %>% 
  tally() %>% 
  mutate(percent = 100*(n/sum(n)))

sitb_detected %>% 
  mutate(any_detect = factor(case_when(
    
    any_detect == FALSE ~ "No SITB",
    any_detect == TRUE ~ "SITB",
    TRUE ~ NA_character_
    
  ))) %>% 
conf_mat(truth = label, estimate = any_detect) %>% 
  summary()


```
```{r looking at breakdown of number of risk words used in the tweet}

sitb_detected %>% 
  group_by(label, sum_detect) %>% 
  tally() %>% 
  mutate(percent = 100*(n/sum(n)))

```

```{r using just the presence absence and sum data to predict label}

# Doing a reproducible training/testing split

set.seed(33)
split_sitb <- initial_split(sitb_detected, prop = 0.8, strata = label)

train_sitb <- training(split_sitb)
test_sitb <- testing(split_sitb)

# Creating a boosted tree model

xgb_mod <- boost_tree(
  trees = 1000, 
  tree_depth = tune(), min_n = tune(), 
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(), mtry = tune(),         ## randomness
  learn_rate = tune(),                         ## step size
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

# Create recipe

rec_boost <- 
  recipe(label ~ ., data = train_sitb) %>% 
  step_tokenize(tweet) %>%
  step_tokenfilter(tweet, max_tokens = 1e3) %>%
  step_tfidf(tweet)

## And add the recipe + model to workflow

xgb_wf <- workflow() %>%
  add_recipe(rec_boost) %>%
  add_model(xgb_mod)

# We'll use bayesian optimization to find hyperparameters

xgb_set <- parameters(xgb_wf) %>% 
  update(mtry = mtry(c(2L, 20L)))

# Let's create cv folds

set.seed(33)
sitb_folds <- vfold_cv(train_sitb, strata = label, repeats = 5)

# Setting up multicore

doMC::registerDoMC(cores = 7)

# Tuning

keep_pred <- control_resamples(save_pred = T)

tic()
set.seed(33)
xgb_tune_rs <-
  xgb_wf %>% 
  tune_bayes(
    resamples = sitb_folds,
    param_info = xgb_set,
    initial = 5,
    iter = 20,
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 5, verbose = TRUE)
  )
toc()

```


```{r running the final boosted tree model with best hyperparameters}

best_auc <- select_best(xgb_tune_rs, "roc_auc")

final_xgb <- xgb_wf %>% 
  finalize_workflow(best_auc)

## Once hyperparameters are selected in ~45 minutes, the model fitting itself only takes ~2 minutes on 7 cores

tic()
set.seed(33)
boost_fit_rs <-
  final_xgb %>% 
  fit_resamples(sitb_folds, control = keep_pred)
toc()

boost_fit_rs %>% 
  collect_metrics(summarize = TRUE)

xgb_pred <- collect_predictions(boost_fit_rs, summarize = TRUE)


```

```{r predicting using a neural network}

# Creating a tabnet neural network model

nn_mod <- tabnet(epochs = 50, batch_size = 128) %>%
  set_engine("torch", verbose = TRUE) %>%
  set_mode("classification")

# Create recipe

rec_nn <- 
  recipe(label ~ ., data = train_sitb) %>% 
  step_normalize(all_numeric())

## And add the recipe + model to workflow

nn_wf <- workflow() %>%
  add_recipe(rec_nn) %>%
  add_model(nn_mod)

# Let's create cv folds

set.seed(33)
sitb_folds <- vfold_cv(train_sitb, strata = label, repeats = 5)

# Setting up multicore

doMC::registerDoMC(cores = 7)

# Fitting via cross-validation, took nearly 2.5 hours to run on 7 cores

keep_pred <- control_resamples(save_pred = T)

tic()
set.seed(33)
nn_fit_rs <-
  nn_wf %>% 
  fit_resamples(sitb_folds, control = keep_pred)
toc()

nn_fit_rs %>% 
  collect_metrics(summarize = TRUE)

nn_pred <- collect_predictions(nn_fit_rs, summarize = TRUE)

```

```{r fitting the xgboost model to test data}

## Model actually fits better in the test set (Previous comment was based on a misread of out of fold results, hadn't run anything on the test set yet)

sitb_fit <- last_fit(final_xgb, split_sitb)
collect_metrics(sitb_fit)

```
```{r plotting auc curve}

collect_predictions(sitb_fit) %>%
  group_by(id) %>%
  roc_curve(label, `.pred_No SITB`) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  ) +
  coord_equal()

```
```{r looking at metrics beyond auc}

collect_predictions(sitb_fit) %>%
conf_mat(truth = label, estimate = .pred_class) %>% 
  summary()

```


```{r looking at feature importance}

sitb_imp <- sitb_fit$.workflow[[1]] %>%
  pull_workflow_fit() %>% 
  vip() %>% 
  print()

```


```{r saving the model}

# Use the code from the end of this github doc: https://github.com/juliasilge/modelops-playground/blob/master/train-model/train.md
# Also reference Julia Silge's answer to this question: https://stackoverflow.com/questions/66018457/r-tidymodels-what-objects-to-save-for-use-in-production-after-fitting-a-recipe
# Also, an example plumber API to save the model to if we want/need: https://github.com/juliasilge/modelops-playground/blob/master/crash-api/plumber.R

sitb_wf_model <- sitb_fit$.workflow[[1]]

saveRDS(sitb_wf_model, "sitb-wf-model.rds")

```

```{r}

# Predict on the text of my most recent tweet at time of model fit

tweet_ex <- tribble(~tweet, ~label,
        "One of my machine learning models is taking hours to run, so I'm finally diving into Statistical Rethinking by @rlmcelreath
 

I don't think I've ever read a technical text that cuts to the core of important problems so quickly (while using easy to understand language too!)", "Unknown",
"When people show you who they are, believe them", "Unknown") %>% 
  mutate(label = as.factor(label))
  
tweet_ex_clean <- map_dfc(words, ~{
  
  tweet_ex %>% 
    detect_word(word = .x)
  
}) %>% 
  dplyr::select(-contains("label"),-contains("tweet")) %>% 
  bind_cols(tweet_ex) %>% 
  rowwise() %>% 
  mutate(any_detect = any(c_across(suicid:abus)), # Seeing if any of the words show up in the text (TRUE if yes, FALSE if no words are in the text)
         sum_detect = sum(c_across(suicid:abus), na.rm = T)) %>% # Seeing how many of the words show up in the text
  ungroup() %>% 
  relocate(label, any_detect, sum_detect, tweet, everything()) %>% 
  arrange(desc(sum_detect)) %>% 
  print()

# If we just predict based on the model without getting text data, this tweet looks like a SITB tweet

predict(sitb_wf_model, tweet_ex_clean)

# Cleaning to get text info

tweet_ex_text <- recipe(label ~ ., data = tweet_ex_clean) %>% 
  step_tokenize(tweet) %>%
  step_tokenfilter(tweet, max_tokens = 1e3) %>%
  step_tfidf(tweet) %>% 
  prep() %>% 
  bake(new_data = tweet_ex_clean) %>% 
  bind_cols(tweet_ex_clean %>% dplyr::select(tweet))
  
# Getting probabilities as well as predicted class from model

predict(sitb_wf_model, tweet_ex_text, type = c("prob")) %>% 
  bind_cols(predict(sitb_wf_model, tweet_ex_text, type = c("class")))

?predict

```



## Next Steps

* Work on extending to multiple columns of text (Next version)
* Work on extending to knowing multiple rows are the same person (Next version)

